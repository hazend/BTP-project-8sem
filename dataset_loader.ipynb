{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e762fa37-40c2-4152-a0de-6909e7bc8b33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## **This module is for parsing the `WLASL_v03.json` file and downloading the .mp4 files for each word. Also, the .mp4 files are converted into `np arrays`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41209987-9121-40e6-8348-d1d0edff3b26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0757bfb5-60e2-4f16-ba2e-41559b0c3ac4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading the json file as an `pd` DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15c6a907-976c-4f92-ad0c-d8d2b940afec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json shpe: (2000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>instances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>[{'bbox': [385, 37, 885, 720], 'fps': 25, 'fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drink</td>\n",
       "      <td>[{'bbox': [551, 68, 1350, 1080], 'fps': 25, 'f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>before</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chair</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gloss                                          instances\n",
       "0      book  [{'bbox': [385, 37, 885, 720], 'fps': 25, 'fra...\n",
       "1     drink  [{'bbox': [551, 68, 1350, 1080], 'fps': 25, 'f...\n",
       "2  computer  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...\n",
       "3    before  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...\n",
       "4     chair  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_path = 'dataset_folder'\n",
    "file_name = 'WLASL_v0.3.json'\n",
    "file_path = os.path.join(main_path, file_name)\n",
    "wlasl_df = pd.read_json(file_path)\n",
    "\n",
    "print(\"json shpe: \"+ str(wlasl_df.shape))\n",
    "wlasl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4f185d-2ff3-4f14-bd00-6c11c5244ef2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fetching available videos list from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f273c6a-067d-46ff-afca-5df3046eca16",
   "metadata": {},
   "source": [
    "function to check if the video id is available in the dataset and return the viedos ids of the current instance\n",
    "    \n",
    "    input: instance json list\n",
    "    output: list of videos_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cac1322-5696-4812-bfea-627d170d3e12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_videos_ids(json_list):\n",
    "    videos_list = []    \n",
    "    for ins in json_list:\n",
    "        video_id = ins['video_id']\n",
    "        videos_list.append(video_id)\n",
    "    return videos_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a293ff-a471-4b0b-a028-0e1e88a71774",
   "metadata": {},
   "source": [
    "function to check if the video id is available in the dataset and return the viedos ids and url or any other featrue of the current instance\n",
    "    \n",
    "    input: instance json list\n",
    "    output: list of videos_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c37cabfd-17cd-4430-94b1-3c6eb2aaf5e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_json_features(json_list):\n",
    "    \n",
    "    videos_ids = []\n",
    "    videos_urls = []\n",
    "    for ins in json_list:\n",
    "        video_id = ins['video_id']\n",
    "        video_url = ins['url']\n",
    "        videos_ids.append(video_id)\n",
    "        videos_urls.append(video_url)\n",
    "    return videos_ids, videos_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2249e632-9d55-46b2-851b-a94fa01569d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'{main_path}/{file_name}', 'r') as data_file:\n",
    "    json_data = data_file.read()\n",
    "\n",
    "instance_json = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81d00fba-7326-4d3f-8267-32441d6b5d48",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bbox': [385, 37, 885, 720],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 0,\n",
       "  'signer_id': 118,\n",
       "  'source': 'aslbrick',\n",
       "  'split': 'train',\n",
       "  'url': 'http://aslbricks.org/New/ASL-Videos/book.mp4',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '69241'},\n",
       " {'bbox': [190, 25, 489, 370],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 1,\n",
       "  'signer_id': 90,\n",
       "  'source': 'aslsignbank',\n",
       "  'split': 'train',\n",
       "  'url': 'https://aslsignbank.haskins.yale.edu/dictionary/protected_media/glossvideo/ASL/BO/BOOK-418.mp4',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '65225'},\n",
       " {'bbox': [262, 1, 652, 480],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 2,\n",
       "  'signer_id': 110,\n",
       "  'source': 'valencia-asl',\n",
       "  'split': 'train',\n",
       "  'url': 'https://www.youtube.com/watch?v=0UsjUE-TXns',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '68011'},\n",
       " {'bbox': [123, 19, 516, 358],\n",
       "  'fps': 25,\n",
       "  'frame_end': 60,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 3,\n",
       "  'signer_id': 113,\n",
       "  'source': 'lillybauer',\n",
       "  'split': 'train',\n",
       "  'url': 'https://www.youtube.com/watch?v=1QOYOZ3g-aY',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '68208'},\n",
       " {'bbox': [95, 0, 1180, 720],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 4,\n",
       "  'signer_id': 109,\n",
       "  'source': 'valencia-asl',\n",
       "  'split': 'train',\n",
       "  'url': 'https://www.youtube.com/watch?v=aGtIHKEdCds',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '68012'},\n",
       " {'bbox': [110, 25, 274, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': 2249,\n",
       "  'frame_start': 2150,\n",
       "  'instance_id': 5,\n",
       "  'signer_id': 121,\n",
       "  'source': 'northtexas',\n",
       "  'split': 'val',\n",
       "  'url': 'https://www.youtube.com/watch?v=hjS0dQDgbjo',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '70212'},\n",
       " {'bbox': [153, 38, 395, 360],\n",
       "  'fps': 25,\n",
       "  'frame_end': 3852,\n",
       "  'frame_start': 3732,\n",
       "  'instance_id': 6,\n",
       "  'signer_id': 121,\n",
       "  'source': 'northtexas',\n",
       "  'split': 'train',\n",
       "  'url': 'https://www.youtube.com/watch?v=WGfiiDgrq1I',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '70266'},\n",
       " {'bbox': [16, 2, 235, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 7,\n",
       "  'signer_id': 49,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'train',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_english_grammar.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07085'},\n",
       " {'bbox': [16, 4, 239, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 8,\n",
       "  'signer_id': 49,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'train',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_geography.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07086'},\n",
       " {'bbox': [8, 1, 253, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 9,\n",
       "  'signer_id': 18,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'train',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_geometry.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07087'},\n",
       " {'bbox': [462, 44, 949, 720],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 10,\n",
       "  'signer_id': 31,\n",
       "  'source': 'signschool',\n",
       "  'split': 'train',\n",
       "  'url': 'https://signstock.blob.core.windows.net/signschool/videos/SignSchool%20Book.mp4',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07069'},\n",
       " {'bbox': [29, 4, 227, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 11,\n",
       "  'signer_id': 18,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'train',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_history.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07088'},\n",
       " {'bbox': [22, 0, 226, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 12,\n",
       "  'signer_id': 18,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'train',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_law.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07089'},\n",
       " {'bbox': [34, 2, 229, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 13,\n",
       "  'signer_id': 18,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'train',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_literature.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07090'},\n",
       " {'bbox': [23, 1, 226, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 14,\n",
       "  'signer_id': 18,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'train',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_math.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07091'},\n",
       " {'bbox': [31, 4, 220, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 15,\n",
       "  'signer_id': 49,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'test',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_medicine.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07092'},\n",
       " {'bbox': [25, 0, 220, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 16,\n",
       "  'signer_id': 18,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'test',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_music.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07093'},\n",
       " {'bbox': [234, 17, 524, 414],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 17,\n",
       "  'signer_id': 36,\n",
       "  'source': 'startasl',\n",
       "  'split': 'train',\n",
       "  'url': 'https://s3-us-west-1.amazonaws.com/files.startasl.com/asldictionary/book.mp4',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07068'},\n",
       " {'bbox': [22, 2, 231, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 18,\n",
       "  'signer_id': 18,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'val',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_photography.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07094'},\n",
       " {'bbox': [3, 2, 260, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 19,\n",
       "  'signer_id': 18,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'test',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_science.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07095'},\n",
       " {'bbox': [21, 2, 228, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 20,\n",
       "  'signer_id': 18,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'val',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_spelling.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07096'},\n",
       " {'bbox': [26, 3, 226, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 21,\n",
       "  'signer_id': 49,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'train',\n",
       "  'url': 'http://www.aslpro.com/main/b/book.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07097'},\n",
       " {'bbox': [131, 26, 526, 480],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 22,\n",
       "  'signer_id': 59,\n",
       "  'source': 'asldeafined',\n",
       "  'split': 'train',\n",
       "  'url': 'https://media.asldeafined.com/vocabulary/1466684225.687.mp4',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07070'},\n",
       " {'bbox': [21, 3, 231, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 23,\n",
       "  'signer_id': 18,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'val',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_trigonometry.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07098'},\n",
       " {'bbox': [162, 54, 528, 400],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 24,\n",
       "  'signer_id': 12,\n",
       "  'source': 'aslsearch',\n",
       "  'split': 'val',\n",
       "  'url': 'http://www.aslsearch.com/signs/videos/book.mp4',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07099'},\n",
       " {'bbox': [70, 0, 268, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 25,\n",
       "  'signer_id': 14,\n",
       "  'source': 'handspeak',\n",
       "  'split': 'train',\n",
       "  'url': 'https://www.handspeak.com/word/b/book2.mp4',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07071'},\n",
       " {'bbox': [75, 0, 270, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 26,\n",
       "  'signer_id': 14,\n",
       "  'source': 'handspeak',\n",
       "  'split': 'test',\n",
       "  'url': 'https://www.handspeak.com/word/b/book.mp4',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07072'},\n",
       " {'bbox': [64, 0, 273, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 27,\n",
       "  'signer_id': 14,\n",
       "  'source': 'handspeak',\n",
       "  'split': 'train',\n",
       "  'url': 'https://www.handspeak.com/word/b/books-pile.mp4',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07073'},\n",
       " {'bbox': [128, 20, 383, 360],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 28,\n",
       "  'signer_id': 109,\n",
       "  'source': 'asllex',\n",
       "  'split': 'train',\n",
       "  'url': 'https://youtu.be/3-GrhsVs830',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '67424'},\n",
       " {'bbox': [82, 11, 212, 192],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 29,\n",
       "  'signer_id': 11,\n",
       "  'source': 'signingsavvy',\n",
       "  'split': 'train',\n",
       "  'url': 'https://www.signingsavvy.com/signs/mp4/14/14326.mp4',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07074'},\n",
       " {'bbox': [386, 48, 942, 720],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 30,\n",
       "  'signer_id': 5,\n",
       "  'source': 'aslu',\n",
       "  'split': 'train',\n",
       "  'url': 'https://www.youtube.com/watch?v=Kwvw-K6GYW8',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07075'},\n",
       " {'bbox': [362, 43, 945, 720],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 31,\n",
       "  'signer_id': 5,\n",
       "  'source': 'aslu',\n",
       "  'split': 'train',\n",
       "  'url': 'https://www.youtube.com/watch?v=XjWSfh50kAU',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07076'},\n",
       " {'bbox': [25, 4, 223, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 32,\n",
       "  'signer_id': 49,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'train',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_accounting.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07077'},\n",
       " {'bbox': [28, 4, 226, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 33,\n",
       "  'signer_id': 18,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'train',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_algebra.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07078'},\n",
       " {'bbox': [15, 2, 238, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 34,\n",
       "  'signer_id': 49,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'train',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_anatomy.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07079'},\n",
       " {'bbox': [28, 2, 226, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 35,\n",
       "  'signer_id': 18,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'train',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_art_history.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07080'},\n",
       " {'bbox': [23, 2, 226, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 36,\n",
       "  'signer_id': 18,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'train',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_art.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07081'},\n",
       " {'bbox': [30, 3, 228, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 37,\n",
       "  'signer_id': 18,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'train',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_business.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07082'},\n",
       " {'bbox': [0, 3, 260, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 38,\n",
       "  'signer_id': 18,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'val',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_chemistry.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07083'},\n",
       " {'bbox': [29, 4, 225, 240],\n",
       "  'fps': 25,\n",
       "  'frame_end': -1,\n",
       "  'frame_start': 1,\n",
       "  'instance_id': 39,\n",
       "  'signer_id': 18,\n",
       "  'source': 'aslpro',\n",
       "  'split': 'train',\n",
       "  'url': 'http://www.aslpro.com/main/b/book_coloring.swf',\n",
       "  'variation_id': 0,\n",
       "  'video_id': '07084'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_json[0]['instances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "732da6d6-a809-4d77-a7eb-b3aebada76b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'69241'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_videos_ids(instance_json[0]['instances'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "625c0bd3-6fcd-4689-9310-44a20c1c1374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wlasl_df['videos_ids'] = wlasl_df['instances'].apply(get_videos_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f3bd2a4-77da-457b-829c-eb550b63948a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angad\\AppData\\Local\\Temp\\ipykernel_548\\859581442.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  features_df = features_df.append(df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "features_df = pd.DataFrame(columns=['gloss', 'video_id', 'url'])\n",
    "\n",
    "for row in wlasl_df.iterrows():\n",
    "    ids, urls = get_json_features(row[1][1])\n",
    "    word = [row[1][0]] * len(ids)\n",
    "    df = pd.DataFrame(list(zip(word, ids, urls)), columns = features_df.columns)\n",
    "    features_df = features_df.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287550ef-cb36-459e-8c29-ffd2db62ccd9",
   "metadata": {},
   "source": [
    "From the json file, only 3 items are useful for now, therefore extracring them in a `features_df` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00980764-ee4f-4de1-8374-77303d19f105",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>video_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>69241</td>\n",
       "      <td>http://aslbricks.org/New/ASL-Videos/book.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book</td>\n",
       "      <td>65225</td>\n",
       "      <td>https://aslsignbank.haskins.yale.edu/dictionar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book</td>\n",
       "      <td>68011</td>\n",
       "      <td>https://www.youtube.com/watch?v=0UsjUE-TXns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book</td>\n",
       "      <td>68208</td>\n",
       "      <td>https://www.youtube.com/watch?v=1QOYOZ3g-aY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book</td>\n",
       "      <td>68012</td>\n",
       "      <td>https://www.youtube.com/watch?v=aGtIHKEdCds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21078</th>\n",
       "      <td>whistle</td>\n",
       "      <td>63186</td>\n",
       "      <td>https://media.spreadthesign.com/video/mp4/13/9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21079</th>\n",
       "      <td>whistle</td>\n",
       "      <td>63187</td>\n",
       "      <td>https://www.handspeak.com/word/w/whistle.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21080</th>\n",
       "      <td>whistle</td>\n",
       "      <td>63188</td>\n",
       "      <td>https://www.signingsavvy.com/signs/mp4/9/9961.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21081</th>\n",
       "      <td>whistle</td>\n",
       "      <td>63189</td>\n",
       "      <td>http://www.aslpro.com/main/w/whistle.swf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21082</th>\n",
       "      <td>whistle</td>\n",
       "      <td>63190</td>\n",
       "      <td>http://www.aslsearch.com/signs/videos/whistle.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21083 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gloss video_id                                                url\n",
       "index                                                                     \n",
       "0         book    69241       http://aslbricks.org/New/ASL-Videos/book.mp4\n",
       "1         book    65225  https://aslsignbank.haskins.yale.edu/dictionar...\n",
       "2         book    68011        https://www.youtube.com/watch?v=0UsjUE-TXns\n",
       "3         book    68208        https://www.youtube.com/watch?v=1QOYOZ3g-aY\n",
       "4         book    68012        https://www.youtube.com/watch?v=aGtIHKEdCds\n",
       "...        ...      ...                                                ...\n",
       "21078  whistle    63186  https://media.spreadthesign.com/video/mp4/13/9...\n",
       "21079  whistle    63187       https://www.handspeak.com/word/w/whistle.mp4\n",
       "21080  whistle    63188  https://www.signingsavvy.com/signs/mp4/9/9961.mp4\n",
       "21081  whistle    63189           http://www.aslpro.com/main/w/whistle.swf\n",
       "21082  whistle    63190  http://www.aslsearch.com/signs/videos/whistle.mp4\n",
       "\n",
       "[21083 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.index.name = 'index'\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea3bda89-e356-4b12-8705-5ed927edbbdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df.to_csv(f'{main_path}/features_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9cdedf02-17fb-4974-8d98-d8e2b63a408d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['book', 'drink', 'computer', 'before', 'chair', 'go', 'clothes',\n",
       "       'who', 'candy', 'cousin'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = features_df['gloss'].unique()\n",
    "all_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58eeed1-9d71-441a-ac73-6f1659422d9d",
   "metadata": {},
   "source": [
    "Good! Now that the `df` is loaded, let's explore the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b6209-1cc4-4028-ac77-bacab0d4ec11",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4249854-8b26-419d-b0f2-79f4183673c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wlasl_df['samples_num'] = wlasl_df['videos_ids'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8085395f-7098-4562-8a84-54704e1288ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>instances</th>\n",
       "      <th>videos_ids</th>\n",
       "      <th>samples_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>[{'bbox': [385, 37, 885, 720], 'fps': 25, 'fra...</td>\n",
       "      <td>[69241, 65225, 68011, 68208, 68012, 70212, 702...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drink</td>\n",
       "      <td>[{'bbox': [551, 68, 1350, 1080], 'fps': 25, 'f...</td>\n",
       "      <td>[69302, 65539, 70173, 68538, 68042, 68660, 680...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[12306, 68028, 69054, 12328, 12329, 12330, 123...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>before</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[05724, 70348, 68007, 05744, 05746, 05728, 057...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chair</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[09847, 70230, 68580, 70263, 68019, 09865, 098...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gloss                                          instances  \\\n",
       "0      book  [{'bbox': [385, 37, 885, 720], 'fps': 25, 'fra...   \n",
       "1     drink  [{'bbox': [551, 68, 1350, 1080], 'fps': 25, 'f...   \n",
       "2  computer  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "3    before  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "4     chair  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "\n",
       "                                          videos_ids  samples_num  \n",
       "0  [69241, 65225, 68011, 68208, 68012, 70212, 702...           40  \n",
       "1  [69302, 65539, 70173, 68538, 68042, 68660, 680...           35  \n",
       "2  [12306, 68028, 69054, 12328, 12329, 12330, 123...           30  \n",
       "3  [05724, 70348, 68007, 05744, 05746, 05728, 057...           26  \n",
       "4  [09847, 70230, 68580, 70263, 68019, 09865, 098...           26  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlasl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e184837a-9cff-4172-93ff-fa1462970c03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN samples per word: 6\n",
      "MAX samples per word: 40\n"
     ]
    }
   ],
   "source": [
    "print(\"MIN samples per word:\", wlasl_df['samples_num'].min())\n",
    "print(\"MAX samples per word:\", wlasl_df['samples_num'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6086fec3-5e51-4efa-b727-fcc0340510ac",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">gloss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>join</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>caterpillar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>402</td>\n",
       "      <td>complete, shoot, united states, accent, act, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>317</td>\n",
       "      <td>responsibility, a, a lot, abdomen, able, accou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>244</td>\n",
       "      <td>cost, diarrhea, ocean, thermometer, above, acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>233</td>\n",
       "      <td>river, across, actor, agree, alarm, allergy, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>173</td>\n",
       "      <td>exchange, add, airplane, already, also, analyz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>159</td>\n",
       "      <td>accept, adult, after, ago, allow, america, ang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>121</td>\n",
       "      <td>afternoon, age, alone, appointment, australia,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>94</td>\n",
       "      <td>always, animal, argue, baby, back, bake, bath,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>77</td>\n",
       "      <td>example, about, approve, arrive, balance, bana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>40</td>\n",
       "      <td>again, bad, ball, bathroom, blanket, buy, call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>34</td>\n",
       "      <td>backpack, bar, brother, cat, check, class, cry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29</td>\n",
       "      <td>africa, basketball, birthday, brown, but, chea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25</td>\n",
       "      <td>accident, apple, bird, change, color, corn, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>bed, blue, bowling, can, dog, family, fish, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14</td>\n",
       "      <td>all, black, cool, finish, hot, like, many, mot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>fine, help, no, thin, walk, year, yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>cousin, deaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>candy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>clothes, who</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>before, chair, go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gloss                                                   \n",
       "            count                                               join\n",
       "samples_num                                                         \n",
       "6               1                                        caterpillar\n",
       "7             402  complete, shoot, united states, accent, act, a...\n",
       "8             317  responsibility, a, a lot, abdomen, able, accou...\n",
       "9             244  cost, diarrhea, ocean, thermometer, above, acc...\n",
       "10            233  river, across, actor, agree, alarm, allergy, a...\n",
       "11            173  exchange, add, airplane, already, also, analyz...\n",
       "12            159  accept, adult, after, ago, allow, america, ang...\n",
       "13            121  afternoon, age, alone, appointment, australia,...\n",
       "14             94  always, animal, argue, baby, back, bake, bath,...\n",
       "15             77  example, about, approve, arrive, balance, bana...\n",
       "16             40  again, bad, ball, bathroom, blanket, buy, call...\n",
       "17             34  backpack, bar, brother, cat, check, class, cry...\n",
       "18             29  africa, basketball, birthday, brown, but, chea...\n",
       "19             25  accident, apple, bird, change, color, corn, co...\n",
       "20             19  bed, blue, bowling, can, dog, family, fish, gr...\n",
       "21             14  all, black, cool, finish, hot, like, many, mot...\n",
       "22              7              fine, help, no, thin, walk, year, yes\n",
       "23              2                                       cousin, deaf\n",
       "24              1                                              candy\n",
       "25              2                                       clothes, who\n",
       "26              3                                  before, chair, go\n",
       "30              1                                           computer\n",
       "35              1                                              drink\n",
       "40              1                                               book"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_sample_counts = wlasl_df[['gloss', 'samples_num']].groupby('samples_num').agg({\"gloss\":['count', ', '.join]})\n",
    "words_sample_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d59398-f02d-4254-a174-a394a11fd570",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Converting Video files into np.arrays of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e59999-82e3-4d00-a78d-e5b038569fd0",
   "metadata": {},
   "source": [
    "**Pipeline:**\n",
    "\n",
    "    1. Extracting frames from the video files using `OpenCV`\n",
    "    2. Converting the frames into mp.hollistic keypoints\n",
    "    3. Storing each set of keypoints for each frame in a designated video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ebcf3a-eded-4503-80a8-5d528328fd9b",
   "metadata": {},
   "source": [
    "Logic  for getting frames for each video `i` in `features_df['url'][0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c683692-1e9e-41c0-a5ad-383f6e4250cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Open the video file\n",
    "video = cv2.VideoCapture(features_df['url'][0])\n",
    "\n",
    "# Get the frame rate of the video\n",
    "frame_rate = int(round(video.get(cv2.CAP_PROP_FPS)))\n",
    "\n",
    "# Set the desired frame rate (in this case, 10 fps)\n",
    "desired_frame_rate = 10\n",
    "\n",
    "# Set the frame interval to achieve the desired frame rate\n",
    "frame_interval = frame_rate // desired_frame_rate\n",
    "\n",
    "# Initialize variables for the loop\n",
    "success, image = video.read()\n",
    "count = 0\n",
    "\n",
    "# Loop through the video frames and extract frames at the desired frame rate\n",
    "while success:\n",
    "    # for each frame after this particular interval\n",
    "    if count % frame_interval == 0:\n",
    "        cv2.imwrite(\"frame%d.jpg\" % count, image)\n",
    "    success, image = video.read()\n",
    "    count += 1\n",
    "\n",
    "# Release the video object\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e517dbd4-5670-4e37-92ed-a497e3f4c917",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('book', dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = np.array(all_words[0], dtype='object')\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9e3ce27d-7070-48ed-9509-0187ddac2459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_rendering = mp.solutions.drawing_utils\n",
    "\n",
    "model = mp_holistic.Holistic(min_detection_confidence=0.7, min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "55acbc69-013d-4583-b379-3fe10b1fa210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])\n",
    "\n",
    "def mediapipe_detection(IMAGE, MODEL):\n",
    "    # image = cv2.cvtColor(IMAGE, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = MODEL.process(image)\n",
    "    image.flags.writeable = True\n",
    "    # image = cv2.cvtColor(IMAGE, cv2.COLOR_RGB2BGR)\n",
    "    return image, results\n",
    "\n",
    "def render_landmarks(image, results):\n",
    "    mp_rendering.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION , \n",
    "                             mp_rendering.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_rendering.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    mp_rendering.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_rendering.DrawingSpec(color=(80,22,10), thickness=1, circle_radius=4), \n",
    "                             mp_rendering.DrawingSpec(color=(80,44,121), thickness=1, circle_radius=2)\n",
    "                             ) \n",
    "    mp_rendering.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_rendering.DrawingSpec(color=(121,22,76), thickness=1, circle_radius=4), \n",
    "                             mp_rendering.DrawingSpec(color=(121,44,250), thickness=1, circle_radius=2)\n",
    "                             ) \n",
    "    mp_rendering.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_rendering.DrawingSpec(color=(245,117,66), thickness=1, circle_radius=4), \n",
    "                             mp_rendering.DrawingSpec(color=(245,66,230), thickness=1, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ce4af2a8-63d2-4a3a-91a5-c40642b67a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for 1st url, FOR NOW\n",
    "cap = cv2.VideoCapture(features_df['url'][0])\n",
    "# dir for all images\n",
    "image_dir = os.path.join('data', 'Images')\n",
    "\n",
    "action = 'book'\n",
    "# |__>delete with below line\n",
    "# for action in actions:\n",
    "for i in range(1):\n",
    "#    render frame from video\n",
    "    success, frame = cap.read()\n",
    "#    replace frame with hollistic image\n",
    "    image, results = mediapipe_detection(frame, model)\n",
    "    \n",
    "#     makedir for the word\n",
    "    os.makedirs(os.path.join(image_dir, str(action)), exist_ok=True)\n",
    "    images_actions_dir = os.path.join(image_dir, str(action))\n",
    "    count = 0    \n",
    "    # Loop through the video frames and extract frames at the desired frame rate\n",
    "    while success:\n",
    "        # for each frame after this particular interval\n",
    "        if count % frame_interval == 0:\n",
    "            cv2.imwrite(f\"{images_actions_dir}/frame{count}.jpg\", image)\n",
    "        success, frame = cap.read()\n",
    "        # image, results = mediapipe_detection(frame, model)\n",
    "        count += 1\n",
    "    \n",
    "\n",
    "    # # Keypoint extraction and saving\n",
    "    # keypoints = extract_keypoints(results)\n",
    "    # npy_path = os.path.join(path, action, str(sequence), str(frame_num))\n",
    "    # np.save(npy_path, keypoints)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcd075e-a28d-4b5e-a58d-496c5ce83f56",
   "metadata": {},
   "source": [
    "Saves all the frames in designated foler (without keypoints) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d87a41-b57f-4242-b014-30da1d8e9da1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Downloading 1st hundred words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e3806009-d986-43e8-8fd1-bb88aca2b391",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2038\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(100):\n",
    "    sum += wlasl_df['samples_num'][i]\n",
    "samples_of_1st_hundred_words = sum\n",
    "print(samples_of_1st_hundred_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c37d90e8-9462-49bb-b78e-415feba3ef23",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimport cv2\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mlast_gloss = \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mbook\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimage_dir = os.path.join(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mImages\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mvideo_subfile_counter = 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfor i in range(samples_of_1st_hundred_words):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    action = features_df[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mgloss\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m][i]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    if action == last_gloss:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        video_subfile_counter +=1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    else:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        last_gloss = action\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        video_subfile_counter = 1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # Open the video file\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    video = cv2.VideoCapture(features_df[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m][i])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # Initialize variables for the loop\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    success, image = video.read()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    count = 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    os.makedirs(os.path.join(image_dir, str(action)), exist_ok=True)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    images_actions_dir = os.path.join(image_dir, str(action))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    os.makedirs(os.path.join(images_actions_dir, f\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mvideo\u001b[39;49m\u001b[38;5;132;43;01m{video_subfile_counter}\u001b[39;49;00m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m), exist_ok=True)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # Loop through the video frames and extract frames at the desired frame rate\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    while success:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    #     my addition    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        if count \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m 3 == 0:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            image, results = mediapipe_detection(frame, model)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            # render_landmarks(image, results)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            # plt.imshow(image)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            keypoints = extract_keypoints(results)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            npy_path = os.path.join(images_actions_dir, str(f\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mvideo\u001b[39;49m\u001b[38;5;132;43;01m{video_subfile_counter}\u001b[39;49;00m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m), str(count))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            np.save(npy_path, keypoints)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        success, image = video.read()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        count += 1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    #     add 1 image in each folder \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mvideo i \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m for confirmation\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        # cv2.imwrite(f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43mos.path.join(images_actions_dir, str(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mvideo1\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m))}/frame\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;132;43;01m% c\u001b[39;49;00m\u001b[38;5;124;43mount, image)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # Release the video object\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    video.release()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2422\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2420\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m   2421\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[1;32m-> 2422\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\magics\\execution.py:1166\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[0;32m   1164\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1166\u001b[0m all_runs \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n\u001b[0;32m   1168\u001b[0m worst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\timeit.py:206\u001b[0m, in \u001b[0;36mTimer.repeat\u001b[1;34m(self, repeat, number)\u001b[0m\n\u001b[0;32m    204\u001b[0m r \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeat):\n\u001b[1;32m--> 206\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m     r\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\magics\\execution.py:156\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    154\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[1;32m<magic-timeit>:16\u001b[0m, in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "import cv2\n",
    "\n",
    "last_gloss = 'book'\n",
    "image_dir = os.path.join('data', 'Images')\n",
    "video_subfile_counter = 0\n",
    "\n",
    "for i in range(samples_of_1st_hundred_words):\n",
    "    \n",
    "    action = features_df['gloss'][i]\n",
    "    if action == last_gloss:\n",
    "        video_subfile_counter +=1\n",
    "    else:\n",
    "        last_gloss = action\n",
    "        video_subfile_counter = 1\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(features_df['url'][i])\n",
    "\n",
    "    # Initialize variables for the loop\n",
    "    success, image = video.read()\n",
    "    count = 0\n",
    "\n",
    "    os.makedirs(os.path.join(image_dir, str(action)), exist_ok=True)\n",
    "    images_actions_dir = os.path.join(image_dir, str(action))\n",
    "    os.makedirs(os.path.join(images_actions_dir, f'video{video_subfile_counter}'), exist_ok=True)\n",
    "\n",
    "\n",
    "    # Loop through the video frames and extract frames at the desired frame rate\n",
    "    while success:\n",
    "    #     my addition    \n",
    "        if count % 3 == 0:\n",
    "            image, results = mediapipe_detection(frame, model)\n",
    "            # render_landmarks(image, results)\n",
    "            # plt.imshow(image)\n",
    "            keypoints = extract_keypoints(results)\n",
    "            npy_path = os.path.join(images_actions_dir, str(f'video{video_subfile_counter}'), str(count))\n",
    "            np.save(npy_path, keypoints)\n",
    "        success, image = video.read()\n",
    "        count += 1\n",
    "\n",
    "    #     add 1 image in each folder 'video i ' for confirmation\n",
    "        # cv2.imwrite(f\"{os.path.join(images_actions_dir, str('video1'))}/frame%d.jpg\" % count, image)\n",
    "    # Release the video object\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "961169d5-c1b9-4806-966b-d6a8ddbd179a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1662,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(os.path.join(images_actions_dir, 'video1', \"{}.npy\".format(6))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "faced7e9-3483-45ad-9fe6-5809f09cb49d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'book'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "61ca96e3-3765-413e-afc3-a2801d0eb2b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drink'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df['gloss'][40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8967f005-1456-4a8c-b9ee-e8bcb74ee4f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0b498c-81a9-4687-b1b9-278ffa334a5c",
   "metadata": {},
   "source": [
    "Collecting all the actions into a variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0523199e-8746-4b5c-9093-02ec82b9edd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['book', 'drink', 'computer', ..., 'weigh', 'wheelchair', 'whistle'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "03a22d13-8f0b-4c84-865d-ee4f3bbb84c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['book', 'drink', 'computer', 'before', 'chair', 'go', 'clothes',\n",
       "       'who', 'candy', 'cousin', 'deaf', 'fine', 'help', 'no', 'thin',\n",
       "       'walk', 'year', 'yes', 'all', 'black', 'cool', 'finish', 'hot',\n",
       "       'like', 'many', 'mother', 'now', 'orange', 'table', 'thanksgiving',\n",
       "       'what', 'woman', 'bed', 'blue', 'bowling', 'can', 'dog', 'family',\n",
       "       'fish', 'graduate', 'hat', 'hearing', 'kiss', 'language', 'later',\n",
       "       'man', 'shirt', 'study', 'tall', 'white', 'wrong', 'accident',\n",
       "       'apple', 'bird', 'change', 'color', 'corn', 'cow', 'dance', 'dark',\n",
       "       'doctor', 'eat', 'enjoy', 'forget', 'give', 'last', 'meet', 'pink',\n",
       "       'pizza', 'play', 'school', 'secretary', 'short', 'time', 'want',\n",
       "       'work', 'africa', 'basketball', 'birthday', 'brown', 'but',\n",
       "       'cheat', 'city', 'cook', 'decide', 'full', 'how', 'jacket',\n",
       "       'letter', 'medicine', 'need', 'paint', 'paper', 'pull', 'purple',\n",
       "       'right', 'same', 'son', 'tell', 'thursday'], dtype=object)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = np.array(all_words[:100])\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4b7ed279-15b5-4a23-9c1d-df98a0ca63f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'actions' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6850602d-7704-4569-998d-6aaf731e237a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
